{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Update: changing the batch_size from 32 to 128 when warm up the model, adding Kappa loss from this kernel: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'aptos-resnet50-baseline.ipynb', 'data_visualization.py', 'extra_data', 'logs', 'models', 'resnet50', 'sample_submission.csv', 'step1_binary_classification_model.py', 'step2_categorical_classification_model.py', 'submission.csv', 'submission_v2.csv', 'test.csv', 'test_filenames.npy', 'test_images', 'train.csv', 'train_images', 'train_images.zip', 'train_models.py', 'visualization', 'X_test.npy', 'X_train.npy', 'y_train.npy', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../diabetic_retinopathy/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "WORKERS = 0\n",
    "CHANNEL = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SIZE = 300\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21ebdcbe908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../diabetic_retinopathy/train.csv')\n",
    "df_test = pd.read_csv('../diabetic_retinopathy/test.csv')\n",
    "\n",
    "x = df_train['id_code']\n",
    "y = df_train['diagnosis']\n",
    "\n",
    "x, y = shuffle(x, y, random_state=8)\n",
    "y.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32969,)\n",
      "(32969, 5)\n",
      "(5819,)\n",
      "(5819, 5)\n"
     ]
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=NUM_CLASSES)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n",
    "                                                      stratify=y, random_state=8)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(valid_x.shape)\n",
    "print(valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aleju/imgaug\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential([\n",
    "    sometimes(\n",
    "        iaa.OneOf([\n",
    "            iaa.Add((-10, 10), per_channel=0.5),\n",
    "            iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "            iaa.ContrastNormalization((0.9, 1.1), per_channel=0.5)\n",
    "        ])\n",
    "    ),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Crop(percent=(0, 0.1)),\n",
    "    # iaa.Flipud(0.5)\n",
    "],random_order=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Generator(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels, batch_size, is_train=True, mix=False):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.is_train = is_train\n",
    "        self.on_epoch_end()\n",
    "        self.is_mix = mix\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        if(self.is_train):\n",
    "            return self.train_generate(batch_x, batch_y)\n",
    "        return self.valid_generate(batch_x, batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if(self.is_train):\n",
    "            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def mix_up(self, x, y):\n",
    "        lam = np.random.beta(0.2, 0.4)\n",
    "        ori_index = np.arange(int(len(x)))\n",
    "        index_array = np.arange(int(len(x)))\n",
    "        np.random.shuffle(index_array)        \n",
    "\n",
    "        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n",
    "        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n",
    "\n",
    "        return mixed_x, mixed_y\n",
    "\n",
    "    def train_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img_path = \"../diabetic_retinopathy/train_images/\" + sample + '.jpeg'\n",
    "            if os.path.exists(img_path): img = cv2.imread(img_path)\n",
    "            elif os.path.exists(img_path) == False: \n",
    "                img_path = \"../diabetic_retinopathy/train_images/\" + sample + '.png'\n",
    "                if os.path.exists(img_path): img = cv2.imread(img_path)\n",
    "                else: continue\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            img = seq.augment_image(img)\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        if(self.is_mix):\n",
    "            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n",
    "        return batch_images, batch_y\n",
    "\n",
    "    def valid_generate(self, batch_x, batch_y):\n",
    "        batch_images = []\n",
    "        for (sample, label) in zip(batch_x, batch_y):\n",
    "            img_path = \"../diabetic_retinopathy/train_images/\" + sample + '.jpeg'\n",
    "            if os.path.exists(img_path): img = cv2.imread(img_path)\n",
    "            elif os.path.exists(img_path) == False: \n",
    "                img_path = \"../diabetic_retinopathy/train_images/\" + sample + '.png'\n",
    "                if os.path.exists(img_path): img = cv2.imread(img_path)\n",
    "                else: continue\n",
    "            img = cv2.resize(img, (SIZE, SIZE))\n",
    "            batch_images.append(img)\n",
    "        batch_images = np.array(batch_images, np.float32) / 255\n",
    "        batch_y = np.array(batch_y, np.float32)\n",
    "        return batch_images, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, n_out):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                   weights=None,\n",
    "                   input_tensor=input_tensor)\n",
    "    base_model.load_weights('../diabetic_retinopathy/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n",
    "    model = Model(input_tensor, final_output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create callbacks list\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n",
    "\n",
    "epochs = 30; batch_size = 32\n",
    "checkpoint = ModelCheckpoint('../working/Resnet50.h5', monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=9)\n",
    "\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "# callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early]\n",
    "\n",
    "train_generator = My_Generator(train_x, train_y, 128, is_train=True)\n",
    "train_mixup = My_Generator(train_x, train_y, batch_size, is_train=True, mix=True)\n",
    "valid_generator = My_Generator(valid_x, valid_y, batch_size, is_train=False)\n",
    "\n",
    "model = create_model(\n",
    "    input_shape=(SIZE,SIZE,3), \n",
    "    n_out=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference link: https://www.kaggle.com/christofhenkel/weighted-kappa-loss-for-keras-tensorflow\n",
    "def kappa_loss(y_true, y_pred, y_pow=2, eps=1e-12, N=5, bsize=32, name='kappa'):\n",
    "    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n",
    "        Args:\n",
    "            y_pred: 2D tensor or array, [batch_size, num_classes]\n",
    "            y_true: 2D tensor or array,[batch_size, num_classes]\n",
    "            y_pow: int,  e.g. y_pow=2\n",
    "            N: typically num_classes of the model\n",
    "            bsize: batch_size of the training or validation ops\n",
    "            eps: a float, prevents divide by zero\n",
    "            name: Optional scope/name for op_scope.\n",
    "        Returns:\n",
    "            A tensor with the kappa loss.\"\"\"\n",
    "\n",
    "    with tf.name_scope(name):\n",
    "        y_true = tf.to_float(y_true)\n",
    "        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n",
    "        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n",
    "        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n",
    "\n",
    "        pred_ = y_pred ** y_pow\n",
    "        try:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n",
    "        except Exception:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n",
    "\n",
    "        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n",
    "        hist_rater_b = tf.reduce_sum(y_true, 0)\n",
    "\n",
    "        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n",
    "\n",
    "        nom = tf.reduce_sum(weights * conf_mat)\n",
    "        denom = tf.reduce_sum(weights * tf.matmul(\n",
    "            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n",
    "                              tf.to_float(bsize))\n",
    "\n",
    "        return nom*0.5 / (denom + eps) + categorical_crossentropy(y_true, y_pred)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "258/258 [==============================] - ETA: 1:52:42 - loss: 1.69 - ETA: 1:37:22 - loss: 2.08 - ETA: 1:34:32 - loss: 2.08 - ETA: 1:31:03 - loss: 2.13 - ETA: 1:29:54 - loss: 2.11 - ETA: 1:28:30 - loss: 2.10 - ETA: 1:27:32 - loss: 2.10 - ETA: 1:26:13 - loss: 2.21 - ETA: 1:25:29 - loss: 2.09 - ETA: 1:24:48 - loss: 2.09 - ETA: 1:24:45 - loss: 2.12 - ETA: 1:24:13 - loss: 2.09 - ETA: 1:23:50 - loss: 2.13 - ETA: 1:23:22 - loss: 2.07 - ETA: 1:23:06 - loss: 2.06 - ETA: 1:22:48 - loss: 2.01 - ETA: 1:22:49 - loss: 1.97 - ETA: 1:22:48 - loss: 1.93 - ETA: 1:22:41 - loss: 1.91 - ETA: 1:22:36 - loss: 1.88 - ETA: 1:22:30 - loss: 1.85 - ETA: 1:22:21 - loss: 1.82 - ETA: 1:21:51 - loss: 1.78 - ETA: 1:21:47 - loss: 1.75 - ETA: 1:21:26 - loss: 1.73 - ETA: 1:21:03 - loss: 1.70 - ETA: 1:20:52 - loss: 1.68 - ETA: 1:20:31 - loss: 1.66 - ETA: 1:20:20 - loss: 1.64 - ETA: 1:19:55 - loss: 1.62 - ETA: 1:19:34 - loss: 1.60 - ETA: 1:19:18 - loss: 1.58 - ETA: 1:19:00 - loss: 1.56 - ETA: 1:18:43 - loss: 1.54 - ETA: 1:18:16 - loss: 1.52 - ETA: 1:17:59 - loss: 1.50 - ETA: 1:17:50 - loss: 1.49 - ETA: 1:17:28 - loss: 1.47 - ETA: 1:17:02 - loss: 1.46 - ETA: 1:16:43 - loss: 1.44 - ETA: 1:16:20 - loss: 1.43 - ETA: 1:15:58 - loss: 1.42 - ETA: 1:15:38 - loss: 1.41 - ETA: 1:15:18 - loss: 1.40 - ETA: 1:14:56 - loss: 1.38 - ETA: 1:14:39 - loss: 1.37 - ETA: 1:14:19 - loss: 1.36 - ETA: 1:13:57 - loss: 1.35 - ETA: 1:13:37 - loss: 1.35 - ETA: 1:13:14 - loss: 1.34 - ETA: 1:12:53 - loss: 1.33 - ETA: 1:12:33 - loss: 1.32 - ETA: 1:12:20 - loss: 1.31 - ETA: 1:11:55 - loss: 1.31 - ETA: 1:11:31 - loss: 1.30 - ETA: 1:11:09 - loss: 1.29 - ETA: 1:10:47 - loss: 1.28 - ETA: 1:10:31 - loss: 1.27 - ETA: 1:10:09 - loss: 1.27 - ETA: 1:09:49 - loss: 1.26 - ETA: 1:09:25 - loss: 1.25 - ETA: 1:09:06 - loss: 1.25 - ETA: 1:08:44 - loss: 1.24 - ETA: 1:08:23 - loss: 1.23 - ETA: 1:08:05 - loss: 1.23 - ETA: 1:07:42 - loss: 1.22 - ETA: 1:07:22 - loss: 1.22 - ETA: 1:07:02 - loss: 1.21 - ETA: 1:06:44 - loss: 1.21 - ETA: 1:06:22 - loss: 1.21 - ETA: 1:06:04 - loss: 1.20 - ETA: 1:05:42 - loss: 1.20 - ETA: 1:05:21 - loss: 1.19 - ETA: 1:05:02 - loss: 1.19 - ETA: 1:04:41 - loss: 1.19 - ETA: 1:04:19 - loss: 1.18 - ETA: 1:04:00 - loss: 1.18 - ETA: 1:03:40 - loss: 1.17 - ETA: 1:03:19 - loss: 1.16 - ETA: 1:02:57 - loss: 1.16 - ETA: 1:02:34 - loss: 1.16 - ETA: 1:02:14 - loss: 1.16 - ETA: 1:01:52 - loss: 1.15 - ETA: 1:01:30 - loss: 1.15 - ETA: 1:01:09 - loss: 1.15 - ETA: 1:00:48 - loss: 1.14 - ETA: 1:00:31 - loss: 1.14 - ETA: 1:00:11 - loss: 1.14 - ETA: 59:49 - loss: 1.1370 - ETA: 59:29 - loss: 1.13 - ETA: 59:08 - loss: 1.12 - ETA: 58:49 - loss: 1.12 - ETA: 58:29 - loss: 1.12 - ETA: 58:08 - loss: 1.12 - ETA: 57:48 - loss: 1.11 - ETA: 57:26 - loss: 1.11 - ETA: 57:07 - loss: 1.11 - ETA: 56:46 - loss: 1.10 - ETA: 56:29 - loss: 1.10 - ETA: 56:09 - loss: 1.10 - ETA: 55:50 - loss: 1.10 - ETA: 55:30 - loss: 1.09 - ETA: 55:12 - loss: 1.09 - ETA: 54:51 - loss: 1.09 - ETA: 54:30 - loss: 1.09 - ETA: 54:09 - loss: 1.08 - ETA: 53:50 - loss: 1.08 - ETA: 53:31 - loss: 1.08 - ETA: 53:10 - loss: 1.08 - ETA: 52:50 - loss: 1.07 - ETA: 52:29 - loss: 1.07 - ETA: 52:14 - loss: 1.07 - ETA: 51:56 - loss: 1.07 - ETA: 51:39 - loss: 1.07 - ETA: 51:19 - loss: 1.06 - ETA: 51:00 - loss: 1.06 - ETA: 50:40 - loss: 1.06 - ETA: 50:18 - loss: 1.06 - ETA: 49:58 - loss: 1.05 - ETA: 49:38 - loss: 1.05 - ETA: 49:19 - loss: 1.05 - ETA: 48:56 - loss: 1.05 - ETA: 48:34 - loss: 1.05 - ETA: 48:13 - loss: 1.05 - ETA: 47:53 - loss: 1.05 - ETA: 47:31 - loss: 1.04 - ETA: 47:09 - loss: 1.04 - ETA: 46:48 - loss: 1.04 - ETA: 46:28 - loss: 1.04 - ETA: 46:07 - loss: 1.04 - ETA: 45:46 - loss: 1.04 - ETA: 45:24 - loss: 1.03 - ETA: 45:02 - loss: 1.03 - ETA: 44:40 - loss: 1.03 - ETA: 44:19 - loss: 1.03 - ETA: 43:58 - loss: 1.02 - ETA: 43:37 - loss: 1.02 - ETA: 43:14 - loss: 1.02 - ETA: 42:52 - loss: 1.02 - ETA: 42:30 - loss: 1.02 - ETA: 42:09 - loss: 1.02 - ETA: 41:48 - loss: 1.02 - ETA: 41:27 - loss: 1.01 - ETA: 41:06 - loss: 1.01 - ETA: 40:46 - loss: 1.01 - ETA: 40:24 - loss: 1.01 - ETA: 40:02 - loss: 1.01 - ETA: 39:40 - loss: 1.01 - ETA: 39:18 - loss: 1.01 - ETA: 38:57 - loss: 1.00 - ETA: 38:36 - loss: 1.00 - ETA: 38:14 - loss: 1.00 - ETA: 37:52 - loss: 1.00 - ETA: 37:30 - loss: 1.00 - ETA: 37:08 - loss: 1.00 - ETA: 36:46 - loss: 1.00 - ETA: 36:25 - loss: 1.00 - ETA: 36:04 - loss: 1.00 - ETA: 35:41 - loss: 0.99 - ETA: 35:20 - loss: 0.99 - ETA: 34:59 - loss: 0.99 - ETA: 34:38 - loss: 0.99 - ETA: 34:17 - loss: 0.99 - ETA: 33:55 - loss: 0.99 - ETA: 33:34 - loss: 0.99 - ETA: 33:13 - loss: 0.99 - ETA: 32:52 - loss: 0.98 - ETA: 32:31 - loss: 0.98 - ETA: 32:09 - loss: 0.98 - ETA: 31:48 - loss: 0.98 - ETA: 31:27 - loss: 0.98 - ETA: 31:05 - loss: 0.98 - ETA: 30:44 - loss: 0.98 - ETA: 30:23 - loss: 0.98 - ETA: 30:01 - loss: 0.98 - ETA: 29:41 - loss: 0.98 - ETA: 29:19 - loss: 0.98 - ETA: 28:58 - loss: 0.98 - ETA: 28:36 - loss: 0.98 - ETA: 28:14 - loss: 0.98 - ETA: 27:51 - loss: 0.97 - ETA: 27:30 - loss: 0.97 - ETA: 27:09 - loss: 0.97 - ETA: 26:48 - loss: 0.97 - ETA: 26:27 - loss: 0.97 - ETA: 26:05 - loss: 0.97 - ETA: 25:43 - loss: 0.97 - ETA: 25:21 - loss: 0.97 - ETA: 25:00 - loss: 0.97 - ETA: 24:39 - loss: 0.97 - ETA: 24:17 - loss: 0.97 - ETA: 23:55 - loss: 0.96 - ETA: 23:33 - loss: 0.96 - ETA: 23:11 - loss: 0.96 - ETA: 22:49 - loss: 0.96 - ETA: 22:28 - loss: 0.96 - ETA: 22:06 - loss: 0.96 - ETA: 21:45 - loss: 0.96 - ETA: 21:23 - loss: 0.96 - ETA: 21:02 - loss: 0.96 - ETA: 20:40 - loss: 0.96 - ETA: 20:17 - loss: 0.96 - ETA: 19:55 - loss: 0.96 - ETA: 19:33 - loss: 0.96 - ETA: 19:11 - loss: 0.95 - ETA: 18:49 - loss: 0.95 - ETA: 18:27 - loss: 0.95 - ETA: 18:05 - loss: 0.95 - ETA: 17:42 - loss: 0.95 - ETA: 17:21 - loss: 0.95 - ETA: 16:59 - loss: 0.95 - ETA: 16:37 - loss: 0.95 - ETA: 16:15 - loss: 0.95 - ETA: 15:53 - loss: 0.95 - ETA: 15:31 - loss: 0.95 - ETA: 15:10 - loss: 0.95 - ETA: 14:48 - loss: 0.95 - ETA: 14:26 - loss: 0.95 - ETA: 14:04 - loss: 0.95 - ETA: 13:42 - loss: 0.95 - ETA: 13:20 - loss: 0.95 - ETA: 12:58 - loss: 0.94 - ETA: 12:36 - loss: 0.94 - ETA: 12:14 - loss: 0.94 - ETA: 11:53 - loss: 0.94 - ETA: 11:31 - loss: 0.94 - ETA: 11:09 - loss: 0.94 - ETA: 10:48 - loss: 0.94 - ETA: 10:26 - loss: 0.94 - ETA: 10:04 - loss: 0.94 - ETA: 9:43 - loss: 0.9427 - ETA: 9:21 - loss: 0.941 - ETA: 8:59 - loss: 0.940 - ETA: 8:37 - loss: 0.940 - ETA: 8:16 - loss: 0.940 - ETA: 7:54 - loss: 0.939 - ETA: 7:32 - loss: 0.939 - ETA: 7:11 - loss: 0.938 - ETA: 6:49 - loss: 0.938 - ETA: 6:28 - loss: 0.937 - ETA: 6:06 - loss: 0.937 - ETA: 5:44 - loss: 0.937 - ETA: 5:23 - loss: 0.937 - ETA: 5:01 - loss: 0.936 - ETA: 4:40 - loss: 0.935 - ETA: 4:18 - loss: 0.934 - ETA: 3:57 - loss: 0.933 - ETA: 3:35 - loss: 0.933 - ETA: 3:13 - loss: 0.933 - ETA: 2:52 - loss: 0.932 - ETA: 2:30 - loss: 0.931 - ETA: 2:09 - loss: 0.931 - ETA: 1:47 - loss: 0.931 - ETA: 1:26 - loss: 0.930 - ETA: 1:04 - loss: 0.930 - ETA: 43s - loss: 0.930 - ETA: 21s - loss: 0.92 - 5547s 22s/step - loss: 0.9295\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64/258 [======>.......................] - ETA: 1:31:59 - loss: 0.70 - ETA: 1:29:53 - loss: 0.69 - ETA: 1:31:03 - loss: 0.69 - ETA: 1:29:36 - loss: 0.68 - ETA: 1:29:55 - loss: 0.71 - ETA: 1:29:06 - loss: 0.71 - ETA: 1:28:48 - loss: 0.74 - ETA: 1:27:41 - loss: 0.77 - ETA: 1:27:02 - loss: 0.76 - ETA: 1:26:39 - loss: 0.77 - ETA: 1:26:51 - loss: 0.79 - ETA: 1:26:30 - loss: 0.80 - ETA: 1:26:12 - loss: 0.81 - ETA: 1:25:44 - loss: 0.80 - ETA: 1:25:33 - loss: 0.80 - ETA: 1:25:17 - loss: 0.80 - ETA: 1:25:13 - loss: 0.81 - ETA: 1:24:52 - loss: 0.81 - ETA: 1:24:40 - loss: 0.81 - ETA: 1:24:24 - loss: 0.81 - ETA: 1:24:00 - loss: 0.81 - ETA: 1:23:39 - loss: 0.81 - ETA: 1:23:06 - loss: 0.81 - ETA: 1:22:53 - loss: 0.81 - ETA: 1:22:24 - loss: 0.81 - ETA: 1:21:59 - loss: 0.81 - ETA: 1:21:50 - loss: 0.81 - ETA: 1:21:24 - loss: 0.81 - ETA: 1:21:04 - loss: 0.81 - ETA: 1:20:29 - loss: 0.81 - ETA: 1:20:04 - loss: 0.80 - ETA: 1:19:45 - loss: 0.80 - ETA: 1:19:24 - loss: 0.80 - ETA: 1:19:04 - loss: 0.80 - ETA: 1:18:37 - loss: 0.81 - ETA: 7:25:27 - loss: 0.81 - ETA: 7:13:37 - loss: 0.81 - ETA: 7:02:20 - loss: 0.81 - ETA: 6:51:33 - loss: 0.81 - ETA: 6:41:22 - loss: 0.80 - ETA: 6:31:36 - loss: 0.81 - ETA: 6:22:17 - loss: 0.81 - ETA: 6:13:27 - loss: 0.81 - ETA: 6:04:59 - loss: 0.81 - ETA: 5:56:50 - loss: 0.81 - ETA: 5:49:07 - loss: 0.81 - ETA: 5:41:39 - loss: 0.81 - ETA: 5:34:26 - loss: 0.81 - ETA: 5:27:33 - loss: 0.81 - ETA: 5:20:53 - loss: 0.81 - ETA: 5:14:29 - loss: 0.81 - ETA: 5:08:20 - loss: 0.81 - ETA: 5:02:29 - loss: 0.81 - ETA: 4:56:44 - loss: 0.81 - ETA: 4:51:08 - loss: 0.81 - ETA: 4:45:45 - loss: 0.81 - ETA: 4:40:38 - loss: 0.81 - ETA: 4:35:47 - loss: 0.81 - ETA: 4:30:52 - loss: 0.81 - ETA: 4:26:08 - loss: 0.81 - ETA: 4:21:31 - loss: 0.81 - ETA: 4:17:06 - loss: 0.81 - ETA: 4:12:49 - loss: 0.81 - ETA: 4:08:36 - loss: 0.8118"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f18f6eb5fc5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWORKERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;34m\"\"\"Create an infinite generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;34m\"\"\"Create an infinite generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4ea6683714aa>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4ea6683714aa>\u001b[0m in \u001b[0;36mtrain_generate\u001b[1;34m(self, batch_x, batch_y)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../diabetic_retinopathy/train_images/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpeg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../diabetic_retinopathy/train_images/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# warm up model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i in range(-3,0):\n",
    "    model.layers[i].trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(1e-3))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(float(len(train_y)) / float(128)),\n",
    "    epochs=2,\n",
    "    workers=WORKERS, use_multiprocessing=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early]\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            # loss=kappa_loss,\n",
    "            optimizer=Adam(lr=1e-4),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_mixup,\n",
    "    steps_per_epoch=np.ceil(float(len(train_x)) / float(batch_size)),\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=np.ceil(float(len(valid_x)) / float(batch_size)),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    workers=1, use_multiprocessing=False,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../diabetic_retinopathy/sample_submission.csv')\n",
    "model.load_weights('../working/Resnet50.h5')\n",
    "predicted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in tqdm(enumerate(submit['id_code'])):\n",
    "    path = os.path.join('../diabetic_retinopathy/test_images/', name+'.png')\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (SIZE, SIZE))\n",
    "    score_predict = model.predict((image[np.newaxis])/255)\n",
    "    label_predict = np.argmax(score_predict)\n",
    "    predicted.append(str(label_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['diagnosis'] = predicted\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
